{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c719ee8-bac5-4c5e-86d8-02bf5939cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0920 14:03:35.231000 82559 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW  # Use PyTorch's AdamW\n",
    "\n",
    "from transformers import BertConfig, BertModel\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "\n",
    "from csibert_util import CSIBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6509dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "# Check MPS availability\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    print(\"MPS backend is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b31f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c26be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e7c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Multi-Cell CSI Data\n",
    "# multi_cell_data = scipy.io.loadmat('foundation_model_data/multi_cell_csi.mat')['csiMatrix']\n",
    "\n",
    "# Load Mobility CSI Data\n",
    "# mobility_data = scipy.io.loadmat('foundation_model_data/mobility_csi.mat')['csiTimeVarying']\n",
    "\n",
    "# Load MU-MIMO CSI Data\n",
    "# mu_mimo_data = scipy.io.loadmat('foundation_model_data/mu_mimo_csi.mat')['csiMU']\n",
    "\n",
    "# Load Heterogeneous Network Data\n",
    "# heterogeneous_data = scipy.io.loadmat('foundation_model_data/heterogeneous_network_csi.mat')\n",
    "# csi_macro = heterogeneous_data['csiMacro']\n",
    "# csi_small_cell = heterogeneous_data['csiSmallCell']\n",
    "\n",
    "cell_data = scipy.io.loadmat('foundation_model_data/csi_data_massive_mimo.mat')['multi_cell_csi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446c7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess individual CSI matrices\n",
    "def preprocess_csi_matrix(csi_matrix):\n",
    "    \"\"\"\n",
    "    Preprocess CSI data to handle variable-length sequences and retain time, frequency, and spatial dimensions.\n",
    "    \"\"\"\n",
    "    csi_real = np.real(csi_matrix)\n",
    "    csi_imag = np.imag(csi_matrix)\n",
    "    \n",
    "    # Normalize real and imaginary parts\n",
    "    csi_real_normalized = (csi_real - np.mean(csi_real)) / np.std(csi_real)\n",
    "    csi_imag_normalized = (csi_imag - np.mean(csi_imag)) / np.std(csi_imag)\n",
    "\n",
    "    # Combine real and imaginary components\n",
    "    csi_combined = np.stack([csi_real_normalized, csi_imag_normalized], axis=-1)  # Shape: (subcarriers, Tx, Rx, 2)\n",
    "    \n",
    "    # Flatten freq, spatial, and real/imaginary into a single feature dimension\n",
    "    time_dim = csi_combined.shape[0]\n",
    "    feature_dim = np.prod(csi_combined.shape[1:])  # Tx × Rx × 2\n",
    "    csi_combined = csi_combined.reshape(time_dim, feature_dim)  # Shape: (time, feature_dim)\n",
    "    \n",
    "    return csi_combined\n",
    "\n",
    "# Traverse the nested cell structure\n",
    "preprocessed_data = []\n",
    "sequence_lengths = []\n",
    "\n",
    "for cell_idx in range(cell_data.shape[0]):  # Iterate over cells\n",
    "    for ue_idx in range(cell_data.shape[1]):  # Iterate over UEs\n",
    "        ue_data = cell_data[cell_idx, ue_idx]\n",
    "        for scenario in ue_data[0]:  # Each UE has multiple scenarios\n",
    "            processed_csi = preprocess_csi_matrix(scenario)\n",
    "            preprocessed_data.append(processed_csi)\n",
    "            sequence_lengths.append(processed_csi.shape[0])  # Track sequence lengths\n",
    "\n",
    "# Convert to padded 3D array (batch_size, sequence_length, feature_dim)\n",
    "max_sequence_length = max(sequence_lengths)\n",
    "feature_dim = preprocessed_data[0].shape[-1]\n",
    "\n",
    "# Pad sequences dynamically\n",
    "padded_data = np.zeros((len(preprocessed_data), max_sequence_length, feature_dim), dtype=np.float32)\n",
    "attention_masks = np.zeros((len(preprocessed_data), max_sequence_length), dtype=np.float32)\n",
    "for i, sequence in enumerate(preprocessed_data):\n",
    "    seq_len = sequence.shape[0]\n",
    "    padded_data[i, :seq_len, :] = sequence\n",
    "    attention_masks[i, :seq_len] = 1  # Mask for unpadded tokens\n",
    "\n",
    "# Mask data for masked signal prediction task\n",
    "def mask_data(data, mask_ratio=0.15):\n",
    "    mask = np.random.rand(*data.shape[:-1]) < mask_ratio  # Exclude the last dimension (real/imaginary parts)\n",
    "    masked_data = np.copy(data)\n",
    "    masked_data[mask, :] = 0  # Replace masked elements with 0\n",
    "    return masked_data, mask\n",
    "\n",
    "masked_data, mask = mask_data(padded_data)\n",
    "\n",
    "# Ensure consistent data types\n",
    "masked_data = masked_data.astype(np.float32)\n",
    "attention_masks = torch.tensor(attention_masks, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282cfe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963b30c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rh/1c0lrj_x0x956417g86lc4ph0000gn/T/ipykernel_82559/1218273177.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(attention_masks).float()  # Attention masks\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(masked_data).float(),  # Masked inputs\n",
    "    torch.tensor(padded_data).float(),  # Labels (original data)\n",
    "    torch.tensor(attention_masks).float()  # Attention masks\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Define a directory to save the best model\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d03d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model and Optimizer\n",
    "model = CSIBERT(feature_dim=feature_dim, num_hidden_layers=6, num_attention_heads = 6)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=10000\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22aa9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf28d8760742425fb7f3c50b241bf154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with loss 0.3503916948 at epoch 1\n",
      "New best model saved with loss 0.0281172142 at epoch 2\n",
      "New best model saved with loss 0.0215394806 at epoch 3\n",
      "New best model saved with loss 0.0179261808 at epoch 4\n",
      "New best model saved with loss 0.0160691192 at epoch 5\n",
      "New best model saved with loss 0.0151808303 at epoch 6\n",
      "New best model saved with loss 0.0145578961 at epoch 7\n",
      "New best model saved with loss 0.0139608366 at epoch 8\n",
      "New best model saved with loss 0.0134003930 at epoch 9\n",
      "New best model saved with loss 0.0131253135 at epoch 10\n",
      "New best model saved with loss 0.0126402048 at epoch 11\n",
      "New best model saved with loss 0.0122836822 at epoch 12\n",
      "New best model saved with loss 0.0120698611 at epoch 13\n",
      "New best model saved with loss 0.0120004030 at epoch 14\n",
      "New best model saved with loss 0.0117868902 at epoch 15\n",
      "New best model saved with loss 0.0117151182 at epoch 16\n",
      "New best model saved with loss 0.0116124269 at epoch 17\n",
      "New best model saved with loss 0.0115408427 at epoch 18\n",
      "New best model saved with loss 0.0115182137 at epoch 19\n",
      "New best model saved with loss 0.0114585167 at epoch 20\n"
     ]
    }
   ],
   "source": [
    "# Variables to track the best model\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "loss_values = []  # Track loss over iterations\n",
    "# In[10]:\n",
    "for epoch in tqdm(range(1000000)):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        inputs, labels, attention_mask = batch  # Add attention mask\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs, attention_mask=attention_mask)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    # Check if this is the best model\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "        # Save the best model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"best_model.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            \"feature_dim\": feature_dim,  # Save feature_dim\n",
    "            'loss': avg_loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"New best model saved with loss {avg_loss:.10f} at epoch {epoch + 1}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Check if early stopping criteria are met\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. Best loss: {best_loss:.10f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(loss_values) + 1), loss_values, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_loss_vals = pd.DataFrame({\n",
    "    'Epoch': range(1, len(loss_values) + 1),\n",
    "    'Loss': loss_values\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_loss_vals.to_csv('loss_values-12-layers.csv', index=False)\n",
    "\n",
    "df_loss_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
